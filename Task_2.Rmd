---
title: "Task 2 RmD"
output: html_document
date: "2024-11-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn=-1)
```

```{r parameters}
seed = 443
csv_file_two = "data2.csv.gz"
training_size = 0.8 # Proportion of dataset that is to be split for training
packages = list("caret", 
                "randomForest", 
                "tree",
                "glmnet",
                "leaps",
                "bigmemory",
                "biglasso"
                )

```

```{r, include=FALSE}
for (package in packages){
  if(!require(package, character.only = TRUE)){
    install.packages(package, character.only = TRUE)
  } else {
    library(package, character.only = TRUE)
  }
}
```


# Task 2: feature selection

```{r load_data}
set.seed(seed)

# load_data_start_time <- Sys.time()

task_two_df <- read.csv(csv_file_two)

# load_data_end_time <- Sys.time()
# 
# load_data_runtime <- load_data_end_time - load_data_start_time
# print(load_data_runtime) # 1.3 mins


# check_na_start_time <- Sys.time()
# 
# # Checking if there are any rows that have missing values... Keep this hashed unless you want to check, because it takes a while to run
# for (i in 1:nrow(task_two_df)) {
#   if (any(is.na(task_two_df[i, ]))) {
#     print(paste("Row", i, "contains NA values."))
#   }
# }
# 
# check_na_end_time <- Sys.time() # 16.8 mins

# check_na_runtime <- check_na_end_time - check_na_start_time
# print(check_na_runtime) 


# task_two_df$label_as_factor <- as.factor(task_two_df$label)

```

```{r drop_columns with 0 variance}
zero_var_cols <- apply(task_two_df, 2, var) == 0.00
# which(zero_var_cols)
table(zero_var_cols)

task_two_df <- task_two_df[, !zero_var_cols ]

# task_two_df_first_523 <- task_two_df[, 1:523]
```


```{r apply_pca}

pca_start_time <- Sys.time()

# Standardize the data (important for PCA)
task_two_data_scaled <- scale(task_two_df[, -which(names(task_two_df) %in% c("label"))])

# Perform PCA
pca_model <- prcomp(task_two_data_scaled, center = TRUE, scale. = TRUE)

pca_end_time <- Sys.time()
pca_runtime <- pca_end_time - pca_start_time
print(pca_runtime)
```


```{r apply_pca}
pca_data <- as.data.frame(pca_model$x[, 1:800])
pca_data$label <- task_two_df$label  # Add the target variable

# Transform the test data using the PCA model
# gbm_test_data_pca <- as.data.frame(predict(gbm_pca_model, newdata = gbm_test_data_scaled)[, 1:10])
# gbm_test_data_pca$label_as_numeric <- test_data_cleaned_gbm$label_as_numeric  # Add the target variable
```

```{r subset_data}
subset_index = as.integer(ncol(task_two_df)*0.20)

subset_split_indices <- sample(1:ncol(task_two_df), subset_index)
subset_task_two_df <- task_two_df[, subset_split_indices]
subset_task_two_df$label <- task_two_df$label
```



```{r train_test_split}
# Split Data into Test and Train (We should all use the same data)
train_split = as.integer(nrow(task_two_df)*training_size)

train_indices <- sample(1:nrow(task_two_df), train_split)
train_data <- task_two_df[train_indices,]
test_data <- task_two_df[-train_indices,]
```


## T2.1: exploratory data analysis and summary statistics (??? -- need to expand)


```{r}
nrow(task_two_df) # The data has 800 observations
ncol(task_two_df) # The data contains 100,001 variables (50,000-real variables, 50,000-random probes, 1-label)

# Labels represent whether given compound binds to target site on thrombin 
# Possible values are -1 (compound did not bind) and 1 (compound did bind)
table(task_two_df$label) # 772 compounds did not bind and 78 compounds did bind

```


## T2.2: train and evaluate feature selection methods

Train and evaluate feature selection methods with the goal of achieving high 
balanced accuracy using a minimal number of selected features. Use three 
different approaches of your choice that were covered in the course.

### Lasso (Jonathan)

```{r Lasso model}
# train_data_cleaned_lasso <- train_data[, !colnames(test_data) %in% c("label")]
test_data_cleaned_lasso <- test_data[, !colnames(test_data) %in% c("label")]


x_data_sparse <-model.matrix(label ~ ., subset_task_two_df)[, -1]
grid <- 10^seq(10, -2, length = 100)
start_task_two_lasso <- Sys.time()
fit.lasso <-glmnet(x_data_sparse,subset_task_two_df$label, alpha = 1, lambda = grid)

end_task_two_lasso <- Sys.time()
total_lasso_time <- end_task_two_lasso - start_task_two_lasso

plot(fit.lasso)
print(total_lasso_time)


plot(fit.lasso, xvar="lambda", label= TRUE)
plot(fit.lasso, xvar="dev", label= TRUE)
cv.lasso <-cv.glmnet(x_data_sparse, subset_task_two_df$label)

pred.test_lasso <-predict(fit.lasso, test_data_cleaned_lasso)

```

```{r Confusion Lasso}
lasso_confusion_matrix <- table(Predicted = pred.test_lasso, Actual = test_data$label)
print(lasso_confusion_matrix)

lasso_balanced_accuracy <- ((1/2) *(lasso_confusion_matrix[2,2]/(lasso_confusion_matrix[2,2]+lasso_confusion_matrix[1,2]))+ (1/2 *(lasso_confusion_matrix[1,1]/(lasso_confusion_matrix[1,1] + lasso_confusion_matrix[2,1]))))

cat("The balanced accuracy is", lasso_balanced_accuracy, "\n")
```


### Forward stepwise selection (FSS) (???)

```{r, results='hold'}
fss_start_time <- Sys.time()

regfit_fwd <-  regsubsets(label ~ .,
                        data = task_two_df_first_523,
                        nvmax = 170,
                        method = "forward")
reg_summary <- summary(regfit_fwd)

fss_end_time <- Sys.time()
fss_runtime <- fss_end_time - fss_start_time
print(fss_runtime)

par(mfrow=c(2,2))
plot(reg_summary$rss, xlab="Number of Variables", ylab="RSS")

# Plot adjusted R2 vs Number of Variables
plot(reg_summary$adjr2, xlab="Number of Variables", ylab="Adjusted RSq", type="l")
# which_max() function is used to identify the location of the maximum point of a vector
best_model = which.max(reg_summary$adjr2)
# Plot a red dot to indicate the model with the largest adjusted R2
points(best_model, reg_summary$adjr2[best_model], col="red", cex=2, pch=20)

## In a similar fashion, we can plot Cp and BIC
plot(reg_summary$cp, xlab="Number of Variables", ylab="Cp", type="l")
best_model = which.min(reg_summary$cp)
points(best_model, reg_summary$cp[best_model], col="red", cex=2, pch=20)

plot(reg_summary$bic, xlab="Number of Variables", ylab="BIC", type="l")
best_model = which.min(reg_summary$bic)
points(best_model, reg_summary$bic[best_model], col="red", cex=2, pch=20)

```





```{r, fig.height = 20, fig.width = 50, fig.align = "center"}
par(mfrow = c(2, 2))
plot(regfit_fwd, scale = "r2")
plot(regfit_fwd, scale = "adjr2")
plot(regfit_fwd, scale = "Cp")
plot(regfit_fwd, scale = "bic")
```



### Backward stepwise selection (BSS) (???)

```{r}

```



## T2.3: additional feature selection methods

Train and evaluate up to three additional feature selection methods, 
other than those in T2.2, which may include methods not covered in the course, 
with the goal of achieving high balanced accuracy using a minimal number of 
selected features. Provide an explanation of each new method.

For T2.2 and T2.3, your evaluation results should include the balanced accuracy 
and the number of selected features achieved by each method for various numbers 
of selected features. You may also compare the balanced accuracy achieved 
by different methods for a similar number of selected features.

### Elastic net (not covered in class) (???)

```{r}

```


### [[Tree-Based models]] (i.e., either Random Forest or LightGBM) (???)

```{r}

```


### (Sparse?) SVM (???)

Is the non-sparse SVM a feature-selection method?

```{r}

```




