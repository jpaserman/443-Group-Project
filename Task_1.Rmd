---
title: "Task 1 RmD"
output: html_document
date: "2024-11-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn=-1)
```

```{r parameters}
seed = 443
csv_file_one = "data1.csv"
packages = list("caret", 
                "randomForest",
                "tree",
                "dplyr",
                "tidyr", "caret", "gbm"
)

```

```{r, include=FALSE}
for (package in packages){
  if(!require(package, character.only = TRUE)){
    install.packages(package, character.only = TRUE)
  } else {
    library(package, character.only = TRUE)
  }
}
```

# Task 1: binary classification

```{r}
task_one_df <- read.csv(csv_file_one)

str(task_one_df)
task_one_df$label_as_factor <- as.factor(task_one_df$label)
```

## T1.1: exploratory data analysis and summary statistics (Peter?)

```{r}
table(task_one_df$label)
library(ggplot2)
nrow(task_one_df)
ncol(task_one_df)

mean_table <- task_one_df %>% 
  
  select(!label) %>%
  
  group_by(label_as_factor) %>%
  
  summarise(across(everything(), mean, na.rm = TRUE)) %>% 
  
  pivot_longer(cols = -label_as_factor, names_to = 'genes', values_to = 'mean_value') %>%
  
  pivot_wider(names_from = label_as_factor, values_from = mean_value) %>%
  
  mutate(diff = abs(`CD4+T` - TREG)) %>% 
  
  arrange(desc(diff))
  
  
## Checking if there are any rows that have missing values... Keep this hashed unless you want to check, because it takes a while to run
# for (i in 1:nrow(task_one_df)) {
#   if (any(is.na(task_one_df[i, ]))) {
#     print(paste("Row", i, "contains NA values."))
#   }
# }

twenty_random_columns <- sample(names(task_one_df)[-1], 20)

## Create boxplots for the random sample of columns
for (column in twenty_random_columns) {
    p <- ggplot(task_one_df, aes_string(x = "label", y = column)) +
        geom_jitter(width = 0.2, height = 0) +  # Use jitter to avoid overplotting
        ggtitle(paste("Scatter Plot of", column, "by Label")) +
        theme_minimal()
    print(p)
}

# Split Data into Test and Train (We should all use the same data)
train_indeces <-sample(1:nrow(task_one_df), 3829) # 3829 is 70% of the data
train_data <- task_one_df[train_indeces,]
test_data <-task_one_df[-train_indeces,]
```

## T1.2: training and evaluating on various classifiers

### Without PCA

#### Linear Discriminant Analysis (LDA) (Imar)

```{r}

```

#### Logistic classifier (Imar)

```{r}

```

#### Quadratic Discriminant Analysis (QDA) (Chi)

```{r}

```

#### Nearest Neighbor Classifier (k-NN) (Chi)

```{r}

```

#### Gradient Boosting Decision Trees (GBDT) (Jonathan)
```{r}
#Number of trees
num_trees = 100
# Define grid of lambda (shrinkage) values to evaluate
lambda_grid <- c(0.001, 0.01,0.03,0.05)

# Initialize a vector to store test errors for each lambda
test_errors <- numeric(length(lambda_grid))
train_data$label_as_numeric <- ifelse(train_data$label == "CD4-positive", 1, 0)
test_data$label_as_numeric <- ifelse(test_data$label == "CD4-positive", 1, 0)
train_data <- train_data[, !(names(train_data) %in% c("label"))]


# Loop over each lambda value
for (i in seq_along(lambda_grid)) {
  lambda <- lambda_grid[i]
  
  # Train the gbm model with the current lambda (shrinkage) value
  gbm_model <- gbm(label_as_numeric ~ ., data = train_data, 
                 distribution = "bernoulli", 
                 n.trees = num_trees, 
                 interaction.depth = 4, 
                 shrinkage = lambda, 
                 cv.folds = 5, 
                 verbose = FALSE)
  
  predictions <- predict(gbm_model, newdata = test_data, n.trees = num_trees, type = "response")
  
  predicted_classes <- ifelse(predictions > 0.5, 1, 0)  # 1 for CD4-positive, 0 for Treg
  
  # Calculate the Mean Squared Error on the test set
  test_errors[i] <- mean((predictions - test_data$label_as_numeric)^2)
}
```


#### Random Forest (Jonathan)
```{r}
## Running Tree on all the variables on train data
tree.rna_features <- tree(label_as_factor ~ ., split="deviance", data = train_data)
summary(tree.rna_features)
plot(tree.rna_features)
text(tree.rna_features, pretty = 0, cex = 1)

## Predict on Test variables
tree.pred <-predict(tree.rna_features, test_data, type="class")

## Mis-classification Rate and Confusion Matrix
table(tree.pred,test_data$label_as_factor)
mean(tree.pred!=test_data$label_as_factor)

```

```{r}
cv.rna_data <- cv.tree(tree.rna_features)
plot(cv.rna_data$size, cv.rna_data$dev, type ='b')
```

Above we use a  tree search to find....  When using the GBDT, we get that there are 11 features that are the most important to classifying whether a cell is a T Regulatory Cell or a CD4-positive cell. However, we can see based on the tree that there are certain features that appear more than once. Based on the tree plot, we can determine that the most important regressor that helps determine if a cell is a Regulatory T cell or a CD4-positive cell is the IL7R. From the National Library of medicine ("https://www.ncbi.nlm.nih.gov/gene/3575"), IL7R is a protein encoded by a gene that plays a critical role in the development of lymph nodes. Based on the analysis above, we decided to create a Random Forest regression that will have 14 terminal nodes. 

```{r}
rna_features.test <- test_data$label_as_factor
rf.rna_features <-randomForest(label_as_factor~., data=train_data, mtry=14, importance=TRUE, n.tree = 5000)
yhat.rf <-predict(rf.rna_features, newdata=test_data)

# Calculate precision, recall, F1-score (using `caret` package)
library(caret)
performance_metrics <- confusionMatrix(yhat.rf, test_data$label_as_factor)
print(performance_metrics)

```
Using a random forest tree model, we see that the accuracy of the model was 0.9312 percent. Which is quite accurate! 

#### Support Vector Machine (SVM) (Peter)

```{r}

```

### With PCA

#### Linear Discriminant Analysis (LDA) (Imar)

```{r}

```

#### Logistic classifier (Imar)

```{r}

```

#### Quadratic Discriminant Analysis (QDA) (Chi)

```{r}

```

#### Nearest Neighbor Classifier (k-NN) (Chi)

```{r}

```

#### Gradient Boosting Decision Trees (GBDT) (Jonathan)

```{r}

```

#### Random Forest (Jonathan)

```{r}

```

#### Support Vector Machine (SVM) (Peter)

```{r}

```

## T1.3: Improving F1 Score (???)

Train and evaluating three classifiers of our choice with the goal of improving
the F1 score (can use methods like bagging, boosting, and regularization).

```{r}

```


## T1.4: Implement predictor (???)

Choose the best approach from those above tested and implement our predictor
as a function of our code.

```{r}

```


